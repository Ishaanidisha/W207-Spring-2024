{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f27e1e",
   "metadata": {},
   "source": [
    "# Lab 07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2062436a",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your homework will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions)\n",
    "* Upload your .ipynb file to Gradescope when done\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d390f",
   "metadata": {},
   "source": [
    "#### ``Objectives``\n",
    "1. Implement a Decision Forest for land cover classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15251984",
   "metadata": {},
   "source": [
    "#### ``Motivation``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a620db",
   "metadata": {},
   "source": [
    "Land cover classification using machine learning (ML) techniques is important for several reasons, spanning environmental monitoring, resource management, urban planning, disaster response, and scientific research. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec1211",
   "metadata": {},
   "source": [
    "#### ``Data``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87c3b0",
   "metadata": {},
   "source": [
    "In this assignment, you will use the EuroSAT dataset, consisting of Sentinel-2 RGB satellite images of 10 classes with 27000 labeled and geo-referenced samples. \n",
    "\n",
    "The dataset is hosted by [TensorFlow Data Collections](https://www.tensorflow.org/datasets/catalog/eurosat). To avoid any data versioning issues, we have downloaded the data for you (please see below).\n",
    "\n",
    "`Download` link: [images + labels](https://drive.google.com/file/d/131GuYn092OlWKGopsT8arQoDreneU7SZ/view?usp=share_link). Once you unzip the file, you will see that the name of each subfolder represents the land cover classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812dd66",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364f3c5",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #used to supress the tf version warning. \n",
    "\n",
    "# FILL IN CODE HERE #\n",
    "DATA_PATH = \"./EuroSAT\" # replace with your path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07097f",
   "metadata": {},
   "source": [
    "^ make sure to replace DATA_PATH with the path to the directory where you saved the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157921a",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d745be",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 1 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f6e96",
   "metadata": {},
   "source": [
    "Let's load the 2D images and their corresponding labels. Implement the `load_data` function according to the following guidelines:\n",
    "- to read label and image names: use the os library (in particular the os.listdir() and os.path.join() methods)\n",
    "- to load an image: use the load_image() method (see list of imported libraries)\n",
    "- to transform images to arrays: use the img_to_array() method (see list of imported libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data):\n",
    "    '''Load 2D images and their corresponding labels\n",
    "    Parameters:\n",
    "    path_to_data (str): This is the path to data\n",
    "    \n",
    "    Returns:\n",
    "    images (np.ndarray): A numpy array of shape (N, 64, 64, 3)\n",
    "    labels (np.ndarray): A numpy array of shape (N)\n",
    "    \n",
    "    '''\n",
    "    ## load images and labels\n",
    "    # FILL IN CODE HERE #  \n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels. Print shapes\n",
    "\n",
    "images, labels = load_data(DATA_PATH)\n",
    "print(\"Shape of images \", images.shape)\n",
    "print(\"Shape of labels \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce6f48",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66780fdc",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 2 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70eb55",
   "metadata": {},
   "source": [
    "Plot the land cover class distribution. Are the classes balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6450fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN CODE HERE # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2c0ea",
   "metadata": {},
   "source": [
    "Comment on class balance: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4d367",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 3 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99059e9f",
   "metadata": {},
   "source": [
    "Inspect (print) one image from each class. What land classes do you think a Decision Tree classifier is more likely to confuse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732f461",
   "metadata": {},
   "source": [
    "Most confused land classes: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5fd6db",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655c129",
   "metadata": {},
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(list(set(labels))) # fit on unique labels\n",
    "encoded_labels = encoder.transform(labels) # apply to labels array (will get labels from 0 to 9)\n",
    "encoded_labels_classes = list(encoder.classes_) # store mapping generated by the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25724f",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 4 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461fe80",
   "metadata": {},
   "source": [
    "Create train, validation, and test data. Implement the `split_data` function according to the following guidelines:\n",
    "- shuffle images and labels before spliting the data\n",
    "- use a 60/20/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(images, labels, split):\n",
    "    '''Split data into train, validation and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    images  (np.ndarray): Images of shape (N, 64, 64, 3)\n",
    "    labels (np.ndarray): Labels of shape (N,)   \n",
    "    split (tuple): 3 values summing to 1 defining split of train, validation and test sets\n",
    "    \n",
    "    Returns:\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 64, 64, 3)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_val (np.ndarray): Val images of shape (N_val, 64, 64, 3)\n",
    "    y_val (np.ndarray): Val labels of shape (N_val,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 64, 64, 3)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "    \n",
    "    '''\n",
    "    # NOTE: Each time you run this cell, you'll re-shuffle the data. The ordering will be the same due to the random seed generator \n",
    "    tf.random.set_seed(1234)\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    # shuffle data\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    # create data splits\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define splits\n",
    "split = (0.6, 0.2, 0.2)\n",
    "\n",
    "# Create train, val, test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(images, encoded_labels, split)\n",
    "\n",
    "# Print shapes\n",
    "print('Shape of train images ', X_train.shape)\n",
    "print('Shape of train labels ', y_train.shape)\n",
    "\n",
    "print('Shape of val images ', X_val.shape)\n",
    "print('Shape of train labels ', y_val.shape)\n",
    "\n",
    "print('Shape of test images ', X_test.shape)\n",
    "print('Shape of test labels ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d145c79",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 5 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f10a6",
   "metadata": {},
   "source": [
    "Perform image transformation and augmentation. \n",
    "\n",
    "<span style=\"color:green\"> Step 1: </span> Implement the `data_preprocessing()` function according to the following guidelines:\n",
    "\n",
    "- Applied on training set only: \n",
    "    - create additional copies of the training images by applying the following augmentation techniques to each image: adjust brightness by adding DELTA=0.3 to the pixel values, then adjust contrast to CONTRAST_FACTOR=3, then flip left right (Hint: use the methods available in the tf.image module).\n",
    "    - concatenate the augmented images to the original training images. Note that the train set should be double in size after data augmentation, i.e., 32400 images and labels.\n",
    "    \n",
    "    \n",
    "- Applied on training, validation, and test sets: normalize all pixel values by dividing by 255.0.\n",
    "    \n",
    "<span style=\"color:green\"> Step 2: </span> Comment on the importance of adding augmented images to training data (be sure to justify why you don't augment the validation and test sets as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(X, y, data_partition='train'):\n",
    "    '''Apply transformations and augmentations to training, validation, and test dat;\n",
    "    \n",
    "    Parameters:\n",
    "    X  (np.ndarray): Images of shape (N, 64, 64, 3)\n",
    "    y (np.ndarray): Labels of shape (N,)   \n",
    "    data_partition (str): \"train\"\n",
    "    \n",
    "    Returns:\n",
    "    X (np.ndarray): Preprocessed images of shape (N, 64, 64, 3)\n",
    "    y (np.ndarray): Labels of shape (N,)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    CONTRAST_FACTOR = 3\n",
    "    DELTA = 0.3\n",
    "    \n",
    "    # image augmentation on training data\n",
    "    if data_partition==\"train\":\n",
    "        # adjust brightness\n",
    "        X_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # adjust contrast\n",
    "        X_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # random flip\n",
    "        X_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # concatenate original X and augmented X_aug data\n",
    "        X = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # concatenate y_train (note the label is preserved)\n",
    "        y_augm = y\n",
    "        y = tf.concat([y, y_augm],axis=0)\n",
    "\n",
    "        # shuffle X and y, i.e., shuffle two tensors in the same order\n",
    "        shuffle = tf.random.shuffle(tf.range(tf.shape(X)[0], dtype=tf.int32))\n",
    "        X = tf.gather(X, shuffle).numpy() # transform X back to numpy array instead of tensor\n",
    "        y = tf.gather(y, shuffle).numpy() # transform y back to numpy array instead of tensor\n",
    "        \n",
    "        \n",
    "    # rescale image by dividing each pixel by 255.0 \n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525690c",
   "metadata": {},
   "source": [
    "Comment on the importnace of adding augmented images to training data (be sure to justify why you don't augment the validation and test sets as well): [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3aacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data preprocessing\n",
    "X_train, y_train = data_preprocessing(X_train, y_train, data_partition='train')\n",
    "X_val, y_val = data_preprocessing(X_val, y_val, data_partition='val')\n",
    "X_test, y_test = data_preprocessing(X_test, y_test, data_partition='val')\n",
    "\n",
    "# Print shapes\n",
    "print('Shape of train images ', X_train.shape)\n",
    "print('Shape of train labels ', y_train.shape)\n",
    "print('Shape of val images ', X_val.shape)\n",
    "print('Shape of test images ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140bc52",
   "metadata": {},
   "source": [
    "Reshape training, val, and test data (to be compatible with sklearn Decision Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of features (multiply RGB features)\n",
    "features_shape = X_train[:, :, :, 0].shape[1] * X_train.shape[2] * X_train.shape[3]\n",
    "print('Total number of features used for Decision Forests', features_shape)\n",
    "\n",
    "# Reshape data\n",
    "X_train_re = X_train.reshape(X_train.shape[0], features_shape)\n",
    "X_val_re = X_val.reshape(X_val.shape[0], features_shape)\n",
    "X_test_re = X_test.reshape(X_test.shape[0], features_shape)\n",
    "\n",
    "# Print shapes\n",
    "print('Shape of train images ', X_train_re.shape)\n",
    "print('Shape of train labels ', y_train.shape)\n",
    "print('Shape of val images ', X_val_re.shape)\n",
    "print('Shape of test images ', X_test_re.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd1c50",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff707c9b",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 6 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c77898",
   "metadata": {},
   "source": [
    "Implement a Decision Forest classifier according to the following guidelines (let's call this model our baseline classifier):\n",
    "    \n",
    "- Use the RandomForestClassifier class available in the sklearn.ensemble module\n",
    "- Set the following argument values:\n",
    "    - n_estimators=2,\n",
    "    - n_jobs=1\n",
    "    - random_state=7\n",
    "    - max_depth=8\n",
    "- Train the model on (X_train_re, y_train) data\n",
    "- Evaluate the accuracy of the model on (X_train_re, y_train) and (X_val_re, y_val) data. Comment on model performance on training vs. validation datasets. Does the model generalize well?\n",
    "- Plot the confusion matrix using (y_val, y_val_pred) data. Comment on the classes that the model confuses the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be5347",
   "metadata": {},
   "source": [
    "Comment on model accuracy on training vs. validation data: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e2527",
   "metadata": {},
   "source": [
    "Does the model generalize well?: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ab0bb",
   "metadata": {},
   "source": [
    "Comment on the classes that the model confuses the most: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86a652",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 7 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a956c9f",
   "metadata": {},
   "source": [
    "Implement a Decision Forest classifier that improves the validation set accuracy performance of the baseline model implemented above by at least 10% (the more you can improve the better). The model should also generalize well (the performance difference between the training and validation sets should be at most 10%). Also, be sure to follow these guidelines: \n",
    "    \n",
    "- Use the RandomForestClassifier or the GradientBoostingClassifier available in the sklearn.ensemble module\n",
    "- Be explicit on how your implementation is different compared to the baseline classifier:\n",
    "    - different argment values for the baseline model (RandomForestClassifier)?\n",
    "    - different Decision Forest classifier?\n",
    "    - different data preprocessing procedure?\n",
    "    - a combination of the three points above\n",
    "    - anything else?\n",
    "- Train the model on (X_train_re, y_train) data\n",
    "- Evaluate the model's accuracy on (X_val_re, y_val) data. Comment on training vs. validation performance relative to baseline model.\n",
    "- Does your model generalize well?\n",
    "- Plot confusion matrix using the (y_val, y_val_pred) data. Comment on the classes the model confuses the most relative to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf2 = ''\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3124a",
   "metadata": {},
   "source": [
    "How your implementation is different compared to the baseline classifier: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93946421",
   "metadata": {},
   "source": [
    "Comment on training vs. validation performance relative to baseline model: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3b817",
   "metadata": {},
   "source": [
    "Does the model generalize well? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2cb2f6",
   "metadata": {},
   "source": [
    "Comment on the classes the model confuses the most relative to the baseline: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161fcbc",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Evaluation (on test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a44a2c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 8 (2 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1879c5",
   "metadata": {},
   "source": [
    "Report accuracy performance on the test data using the model trained for Exercise 7. How does the test set performance compare with the one reported for the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab7fd9",
   "metadata": {},
   "source": [
    "Comment on test set accuracy vs. validation set accuracy: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49de10",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9a155",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 9 (8 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd83e4e",
   "metadata": {},
   "source": [
    "Would you recommend a Decision Forest for land cover classification? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a404a0c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 10 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed521b",
   "metadata": {},
   "source": [
    "What other ML model would you propose to improve performance over the Decision Forest classifier you implemented for Exercise 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05777099",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Bonus Exercise (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58b2cb",
   "metadata": {},
   "source": [
    "Implement the idea proposed for Exercise 10. Perform hyperparameter tuning using the training and validation sets, then report the model performance on the test data. Does your model generalize well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
